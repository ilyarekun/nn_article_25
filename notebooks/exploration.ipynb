{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..', 'src')))\n",
    "\n",
    "#%pip install -r requirements.txt\n",
    "from data_preprocessing import data_preprocessing_tumor\n",
    "from model import BrainCNN, EarlyStopping\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchbearer\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchbearer import Trial\n",
    "from torchmetrics import Precision, Recall, F1Score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "first try paper CCE, then NLLLoss\n",
    "cce_loss_fn = nn.NLLLoss()\n",
    "cce_logits_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    ">>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    ">>> optimizer.zero_grad()\n",
    ">>> loss_fn(model(input), target).backward()\n",
    ">>> optimizer.step()\n",
    "    def train(model, train_loader, valid_loader, ):\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "important\n",
    "\n",
    "2 combinations should be tested:\n",
    "1. last layer Softmax + loss func nn.NLLLoss\n",
    "2. no last layer and CrossEntropyLoss\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "train_loader, valid_loader, test_loader = data_preprocessing_tumor()\n",
    "num_epochs=100\n",
    "patience=1\n",
    "learning_rate=0.001\n",
    "device=None\n",
    "model = BrainCNN()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "early_stopping = EarlyStopping(patience=5, delta=0.01)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "        \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item() * data.size(0)\n",
    "            \n",
    "    val_loss /= len(valid_loader.dataset) \n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}, Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")   \n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    \n",
    "early_stopping.load_best_model(model)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum.item()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "        \n",
    "            \n",
    "accuracy = 100 * correct / total\n",
    "precision = precision_score(all_targets, all_preds, average='weighted')\n",
    "recall = recall_score(all_targets, all_preds, average='weighted')\n",
    "f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "torch.save(model.state_dict(), \"./braincnn_prototype.weights\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
